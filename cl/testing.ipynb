{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         network: \n",
      "         station: \n",
      "        location: \n",
      "         channel: \n",
      "       starttime: 2017-11-29T22:25:23.000000Z\n",
      "         endtime: 2017-11-29T22:25:39.000000Z\n",
      "   sampling_rate: 1000.0\n",
      "           delta: 0.001\n",
      "            npts: 16001\n",
      "           calib: 1.0\n",
      "            segy: AttribDict({'trace_header': LazyTraceHeaderAttribDict({'unpacked_header': b'\\xfa\\xff\\xff\\xff\\xfa\\xff\\xff\\xff\\xfa\\x03\\x00\\x00\\xfa\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x04\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xccB\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf6\\xff\\xf6\\xffM_3\\x00\\x15\\x8a\\x8a\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x81>\\xe8\\x03\\x03\\x00\\x00\\x00\\x00\\x00\\x01\\x00(\\x00H\\x03\\xe0.\\x01\\x00,\\x01,\\x01\\x04\\x00\\x9d\\x01\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xe1\\x07M\\x01\\x16\\x00\\x19\\x00\\x17\\x00\\x04\\x00 }\\r\\x00\\xd33\\x1fZ\\x00\\x00\\x93\\x13d\\x00\\x00\\x00d\\x00\\x00\\x00D\\xc5\\x00\\x00\\xd8@\\x00\\x00e\\x00\\x00\\x00\\x17\\x001\\x15\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'endian': '<', 'sample_interval_in_ms_for_this_trace': 1000, 'year_data_recorded': 2017, 'day_of_year': 333, 'hour_of_day': 22, 'minute_of_hour': 25, 'second_of_minute': 23})})\n"
     ]
    }
   ],
   "source": [
    "import obspy\n",
    "from obspy.io.segy.core import _read_segy\n",
    "\n",
    "filename = '/home/dnlab/Data-B/1001-1122/1511994323_1018_50500_16600_20171202_220556_632.sgy'\n",
    "stream = _read_segy(filename, headonly=True)\n",
    "print(stream.traces[0].stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.6211255e-03 -8.6097559e-03 -8.6101312e-03 ... -8.6270012e-03\n",
      "  -8.6304834e-03 -8.6225774e-03]\n",
      " [ 4.7923021e+00  1.0675242e+01  9.4782658e+00 ... -1.0837941e-01\n",
      "   1.0161659e-01 -8.5060950e-03]\n",
      " [ 2.6262314e-03  3.3074068e-03  3.3874351e-03 ...  3.0328280e-03\n",
      "   2.8129078e-03  2.5832215e-03]\n",
      " ...\n",
      " [ 2.5407210e-06  2.5832412e-06  2.8842585e-06 ...  7.2876214e-06\n",
      "   7.6792285e-06  6.2379572e-06]\n",
      " [ 3.0551371e-06  2.7638655e-06  2.7422345e-06 ...  5.0419499e-06\n",
      "   4.1835178e-06  4.5364277e-06]\n",
      " [-1.5085160e-06 -2.3389075e-06 -3.2011690e-06 ...  3.6909471e-06\n",
      "   2.0183377e-06  9.0470803e-07]]\n",
      "16001\n",
      "1000.0\n",
      "2017-11-29T22:25:23.000000Z\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import obspy\n",
    "import numpy as np\n",
    "\n",
    "# Load the SEGY file\n",
    "filename = '/home/dnlab/Data-B/1001-1122/1511994323_1018_50500_16600_20171202_220556_632.sgy'\n",
    "stream = obspy.read(filename)\n",
    "\n",
    "# Extract the data and trace header information\n",
    "data = np.array([trace.data for trace in stream.traces])\n",
    "npts = stream.traces[0].stats.npts\n",
    "sampling_rate = stream.traces[0].stats.sampling_rate\n",
    "starttime = stream.traces[0].stats.starttime\n",
    "\n",
    "print(data)\n",
    "print(npts)\n",
    "print(sampling_rate)\n",
    "print(starttime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "---------------------------\n",
      "<utils.DataGenerator object at 0x7f27fb06ffa0>\n",
      "2\n",
      "Finish loading dataset\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as keras\n",
    "from utils import generate_data, DataGenerator\n",
    "from unet import *\n",
    "import flwr as fl\n",
    "\n",
    "params = {'batch_size':1,\n",
    "          'dim':(128,128,128),\n",
    "          'n_channels':1,\n",
    "          'shuffle': True}\n",
    "seismPathT = \"../../data_seismic/fl_test/client1/train/seis/\"\n",
    "faultPathT = \"../../data_seismic/fl_test/client1/train/fault/\"\n",
    "seismPathV = \"../../data_seismic/fl_test/client1/validation/seis/\"\n",
    "faultPathV = \"../../data_seismic/fl_test/client1/validation/fault/\"\n",
    "train_ID = range(100)\n",
    "valid_ID = range(10)\n",
    "x_train, y_train = generate_data(dpath=seismPathT, fpath=faultPathT, data_IDs=train_ID, **params)\n",
    "x_test, y_test = generate_data(dpath=seismPathV, fpath=faultPathV, data_IDs=valid_ID, **params)\n",
    "\n",
    "print(len(x_train))\n",
    "print('---------------------------')\n",
    "\n",
    "train_generator = DataGenerator(dpath=seismPathT,fpath=faultPathT,\n",
    "                                data_IDs=train_ID,**params)\n",
    "valid_generator = DataGenerator(dpath=seismPathV,fpath=faultPathV,\n",
    "                                data_IDs=valid_ID,**params)\n",
    "print(train_generator)\n",
    "print(len(train_generator[0]))\n",
    "\n",
    "print(\"Finish loading dataset\")\n",
    "# model = unet(input_size=(None, None, None,1))\n",
    "# model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 12:25:13.569285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2023-05-16 12:25:18.414927: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.08MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 14s 14s/step - loss: 0.7223 - accuracy: 0.0869\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.7111 - accuracy: 0.1568\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.7020 - accuracy: 0.3148\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.6927 - accuracy: 0.5510\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.6813 - accuracy: 0.7772\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.6659 - accuracy: 0.8785\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.6430 - accuracy: 0.9062\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.6090 - accuracy: 0.9143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.5605 - accuracy: 0.9172\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.4901 - accuracy: 0.9193\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.3997 - accuracy: 0.9206\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.3177 - accuracy: 0.9218\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.3077 - accuracy: 0.9232\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.3687 - accuracy: 0.9234\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.3912 - accuracy: 0.9235\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.3666 - accuracy: 0.9237\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.3272 - accuracy: 0.9241\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.2997 - accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.2937 - accuracy: 0.9263\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.3030 - accuracy: 0.9276\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.3147 - accuracy: 0.9288\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.3202 - accuracy: 0.9294\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.3169 - accuracy: 0.9297\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.3069 - accuracy: 0.9299\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.2954 - accuracy: 0.9299\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.2887 - accuracy: 0.9300\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.2906 - accuracy: 0.9300\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.2968 - accuracy: 0.9301\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.2990 - accuracy: 0.9301\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.2952 - accuracy: 0.9301\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.2887 - accuracy: 0.9301\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.2839 - accuracy: 0.9301\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.2825 - accuracy: 0.9301\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.2833 - accuracy: 0.9301\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.2840 - accuracy: 0.9301\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2829 - accuracy: 0.9301\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 0.2804 - accuracy: 0.9301\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.2786 - accuracy: 0.9301\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 0.2790 - accuracy: 0.9301\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.2786 - accuracy: 0.9301\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2763 - accuracy: 0.9301\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2742 - accuracy: 0.9301\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.2733 - accuracy: 0.9301\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.2725 - accuracy: 0.9301\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.2711 - accuracy: 0.9301\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.2698 - accuracy: 0.9301\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.2693 - accuracy: 0.9301\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2680 - accuracy: 0.9301\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.2666 - accuracy: 0.9301\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.2658 - accuracy: 0.9301\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.2650 - accuracy: 0.9301\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.2641 - accuracy: 0.9301\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.2635 - accuracy: 0.9301\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.2628 - accuracy: 0.9301\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.2621 - accuracy: 0.9301\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.2615 - accuracy: 0.9301\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2609 - accuracy: 0.9301\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2604 - accuracy: 0.9301\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2599 - accuracy: 0.9301\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.2594 - accuracy: 0.9301\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.2591 - accuracy: 0.9301\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2587 - accuracy: 0.9301\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.2583 - accuracy: 0.9301\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.2580 - accuracy: 0.9301\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.2576 - accuracy: 0.9301\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.2573 - accuracy: 0.9301\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.2569 - accuracy: 0.9301\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.2567 - accuracy: 0.9301\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.2563 - accuracy: 0.9301\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.2560 - accuracy: 0.9301\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2557 - accuracy: 0.9301\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.2554 - accuracy: 0.9301\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.2551 - accuracy: 0.9301\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.2549 - accuracy: 0.9301\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2546 - accuracy: 0.9301\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.2543 - accuracy: 0.9301\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2541 - accuracy: 0.9301\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2538 - accuracy: 0.9301\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2536 - accuracy: 0.9301\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2533 - accuracy: 0.9301\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.2531 - accuracy: 0.9301\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.2528 - accuracy: 0.9301\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2526 - accuracy: 0.9301\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.2524 - accuracy: 0.9301\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.2522 - accuracy: 0.9301\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.2520 - accuracy: 0.9301\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2518 - accuracy: 0.9301\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2515 - accuracy: 0.9301\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.2513 - accuracy: 0.9301\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2511 - accuracy: 0.9301\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.2509 - accuracy: 0.9301\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 0.2507 - accuracy: 0.9301\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.2505 - accuracy: 0.9301\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.2506 - accuracy: 0.9301\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 0.2511 - accuracy: 0.9301\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 0.2512 - accuracy: 0.9301\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.2498 - accuracy: 0.9301\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.2509 - accuracy: 0.9301\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.2502 - accuracy: 0.9301\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.2498 - accuracy: 0.9301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26f04c8910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
